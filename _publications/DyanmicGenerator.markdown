---
layout: pub
type: article
key: dyngen
title: >
    Learning Dynamic Generator Model by Alternating Back-Propagation Through Time
author: Xie, Jianwen and Gao, Ruiqi and Zheng, Zilong and Zhu, Song-Chun and Wu, Ying Nian
equalauthor: Xie, Jianwen and Gao, Ruiqi
website: http://www.stat.ucla.edu/~jxie/DynamicGenerator/DynamicGenerator.html
arxiv: 1812.10587
abbr: AAAI'19
award: Spotlight
img: DynamicGenerator/dynamic_generator.gif
code: https://github.com/jianwen-xie/Dynamic_generator
# journal: The Thirty-Third AAAI Conference on Artificial Intelligence (AAAI)
journal: AAAI
year: 2019
abstract: >
    This paper studies the dynamic generator model for spatial-temporal processes such as dynamic textures and action sequences in video data. In this model, each time frame of the video sequence is generated by a generator model, which is a non-linear transformation of a latent state vector, where the non-linear transformation is parametrized by a top-down neural network. The sequence of latent state vectors follows a non-linear auto-regressive model, where the state vector of the next frame is a non-linear transformation of the state vector of the current frame as well as an independent noise vector that provides randomness in the transition. The non-linear transformation of this transition model can be parametrized by a feedforward neural network. We show that this model can be learned by an alternating back-propagation through time algorithm that iteratively samples the noise vectors and updates the parameters in the transition model and the generator model. We show that our training method can learn realistic models for dynamic textures and action patterns.
bibtex: >
    @article{xie2019DG,
        title = {Learning Dynamic Generator Model by Alternating Back-Propagation Through Time},
        author = {Xie, Jianwen and Gao, Ruiqi and Zheng, Zilong and Zhu, Song-Chun and Wu, Ying Nian},
        journal={The Thirty-Third AAAI Conference on Artificial Intelligence (AAAI)},
        year = {2019}
    }    
---