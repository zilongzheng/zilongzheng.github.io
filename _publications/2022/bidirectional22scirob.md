---
layout: publication
type: journal
key: bidirectional22scirob
title: >
    In situ bidirectional human-robot value alignment
author: Yuan*#, Luyao and Gao*, Xiaofeng and Zheng*, Zilong and Edmonds, Mark and Wu, Ying Nian and Rossano, Federico and Lu#, Hongjing and Zhu#, Yixin and Zhu#, Song-Chun
website: https://yzhu.io/publication/teaming2022scirob/
abbr: ScienceRobotics
journal: Science Robotics
supp: https://www.science.org/action/downloadSupplement?doi=10.1126%2Fscirobotics.abm4183&file=scirobotics.abm4183_sm.pdf
video: https://vimeo.com/730025438
code: https://doi.org/10.5068/D1XT3V
year: 2022
selected: true
medias:
    - name: TechXplore
      url: https://techxplore.com/news/2022-08-ai-paradigm-human-robot-collaboration.html
    - name: 科技日报/新华网
      url: http://www.xinhuanet.com/tech/20220714/4d46925b0def47f0914aae9c030bd36b/c.html
abstract: >
    A prerequisite for social coordination is bidirectional communication between teammates, each playing two roles simultaneously: as receptive listeners and expressive speakers. For robots working with humans in complex situations with multiple goals that differ in importance, failure to fulfill the expectation of either role could undermine group performance due to misalignment of values between humans and robots. Specifically, a robot needs to serve as an effective listener to infer human users’ intents from instructions and feedback and as an expressive speaker to explain its decision processes to users. Here, we investigate how to foster effective bidirectional human-robot communications in the context of value alignment—collaborative robots and users form an aligned understanding of the importance of possible task goals. We propose an explainable artificial intelligence (XAI) system in which a group of robots predicts users’ values by taking in situ feedback into consideration while communicating their decision processes to users through explanations. To learn from human feedback, our XAI system integrates a cooperative communication model for inferring human values associated with multiple desirable goals. To be interpretable to humans, the system simulates human mental dynamics and predicts optimal explanations using graphical models. We conducted psychological experiments to examine the core components of the proposed computational framework. Our results show that real-time human-robot mutual understanding in complex cooperative tasks is achievable with a learning model based on bidirectional communication. We believe that this interaction framework can shed light on bidirectional value alignment in communicative XAI systems and, more broadly, in future human-machine teaming systems. An explainable artificial intelligence collaboration framework enables in situ bidirectional human-robot value alignment.
bibtex: >
    @article{
        doi:10.1126/scirobotics.abm4183,
        author = {Luyao Yuan  and Xiaofeng Gao  and Zilong Zheng  and Mark Edmonds  and Ying Nian Wu  and Federico Rossano  and Hongjing Lu  and Yixin Zhu  and Song-Chun Zhu },
        title = {In situ bidirectional human-robot value alignment},
        journal = {Science Robotics},
        volume = {7},
        number = {68},
        pages = {eabm4183},
        year = {2022},
        doi = {10.1126/scirobotics.abm4183},
        URL = {https://www.science.org/doi/abs/10.1126/scirobotics.abm4183},
        eprint = {https://www.science.org/doi/pdf/10.1126/scirobotics.abm4183}
    }
---
